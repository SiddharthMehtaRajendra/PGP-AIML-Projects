{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   ...   EstimatedSalary  Exited\n",
       "0          1    15634602   ...         101348.88       1\n",
       "1          2    15647311   ...         112542.58       0\n",
       "2          3    15619304   ...         113931.57       1\n",
       "3          4    15701354   ...          93826.63       0\n",
       "4          5    15737888   ...          79084.10       0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Surname is also dropped as it is test data provides no impact on assessing customer retention probability\n",
    "data.drop(columns = ['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target set would be the 'isActive' column since it checks whether bank customer is active, which would be useful for\n",
    "validating the possibility of a bank customer staying or leaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'IsActiveMember']\n",
    "Y = data.loc[:, data.columns == 'IsActiveMember']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
       "Index: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation is '0' null values in both training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore         460\n",
       "Geography             3\n",
       "Gender                2\n",
       "Age                  70\n",
       "Tenure               11\n",
       "Balance            6382\n",
       "NumOfProducts         4\n",
       "HasCrCard             2\n",
       "IsActiveMember        2\n",
       "EstimatedSalary    9999\n",
       "Exited                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France' 'Spain' 'Germany']\n",
      "['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "#Checking Categorical Values in X\n",
    "print(data['Geography'].unique())\n",
    "print(data['Gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age     ...       Geography_Spain  Gender_Male\n",
       "0          619   42     ...                     0            0\n",
       "1          608   41     ...                     1            0\n",
       "2          502   42     ...                     0            0\n",
       "3          699   39     ...                     0            0\n",
       "4          850   43     ...                     1            0\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting Categorical Values to Numeric Format, dropping redundant first dummy variable for decorrelation\n",
    "data = pd.get_dummies(data, columns = ['Geography', 'Gender'], dtype = np.int64, drop_first = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      "CreditScore          10000 non-null int64\n",
      "Age                  10000 non-null int64\n",
      "Tenure               10000 non-null int64\n",
      "Balance              10000 non-null float64\n",
      "NumOfProducts        10000 non-null int64\n",
      "HasCrCard            10000 non-null int64\n",
      "IsActiveMember       10000 non-null int64\n",
      "EstimatedSalary      10000 non-null float64\n",
      "Exited               10000 non-null int64\n",
      "Geography_Germany    10000 non-null int64\n",
      "Geography_Spain      10000 non-null int64\n",
      "Gender_Male          10000 non-null int64\n",
      "dtypes: float64(2), int64(10)\n",
      "memory usage: 937.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capping Outliers in the given dataset. We shall only consider features which shall qualify for outlier analysis i.e.\n",
    "#features with continuous values and not features that are categorical, order or count variables as they are ineligible for outlier\n",
    "#analysis.\n",
    "\n",
    "capDf = pd.DataFrame()\n",
    "toCapDf = data.loc[:, ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']]\n",
    "for col in data.columns:\n",
    "    if(data[col].dtype == object):\n",
    "        capDf[col] = data[col]\n",
    "        continue\n",
    "    if(col in toCapDf.columns):\n",
    "        percentiles = toCapDf[col].quantile([0.25,0.75]).values\n",
    "        Q1 = percentiles[0]\n",
    "        Q3 = percentiles[1]\n",
    "        IQR = Q3 - Q1\n",
    "        minCap = Q1 - (IQR) * 1.5\n",
    "        maxCap = Q3 + (IQR) * 1.5\n",
    "        capDf[col] = toCapDf[col][(toCapDf[col] >= minCap) & (toCapDf[col] <= maxCap)]\n",
    "    else:\n",
    "        capDf[col] = data[col]\n",
    "    \n",
    "capDf.dropna(inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>350</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109733.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123602.11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9624</th>\n",
       "      <td>350</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>111098.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>172321.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8723</th>\n",
       "      <td>350</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125823.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>350</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>152677.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>191973.49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>350</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113796.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>351</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4</td>\n",
       "      <td>163146.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>169621.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>358</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8</td>\n",
       "      <td>143542.36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141959.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>359</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6</td>\n",
       "      <td>128747.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146955.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>363</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>146098.43</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100615.14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>365</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>127760.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81537.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8154</th>\n",
       "      <td>367</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6</td>\n",
       "      <td>93608.28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>168816.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>373</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77786.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>376</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157333.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>382</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>179540.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>408</td>\n",
       "      <td>84.0</td>\n",
       "      <td>8</td>\n",
       "      <td>87873.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188484.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7138</th>\n",
       "      <td>430</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6</td>\n",
       "      <td>135392.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>172852.06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>431</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160982.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>168008.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>434</td>\n",
       "      <td>71.0</td>\n",
       "      <td>9</td>\n",
       "      <td>119496.87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125848.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>439</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65535.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9765</th>\n",
       "      <td>445</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2</td>\n",
       "      <td>136770.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43678.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>456</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>165350.61</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140758.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9292</th>\n",
       "      <td>461</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>186445.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>196767.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>476</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1</td>\n",
       "      <td>105303.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>134260.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>486</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9</td>\n",
       "      <td>97009.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85101.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>491</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>95039.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>116471.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>491</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3</td>\n",
       "      <td>107571.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113695.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4849</th>\n",
       "      <td>491</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6</td>\n",
       "      <td>148745.92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17818.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>491</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6</td>\n",
       "      <td>91285.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7032.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5581</th>\n",
       "      <td>494</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85890.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>793</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9</td>\n",
       "      <td>116270.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184243.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>796</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54871.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>799</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>110314.21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37464.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>799</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8</td>\n",
       "      <td>70416.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36483.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>803</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>151659.52</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6930.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>804</td>\n",
       "      <td>71.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>147995.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7139</th>\n",
       "      <td>806</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103945.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6715</th>\n",
       "      <td>808</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10</td>\n",
       "      <td>124577.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169894.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>809</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34164.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9402</th>\n",
       "      <td>810</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3</td>\n",
       "      <td>27288.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110509.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7523</th>\n",
       "      <td>814</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130853.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>816</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6</td>\n",
       "      <td>151858.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72814.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>818</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8</td>\n",
       "      <td>135290.42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63729.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>823</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5</td>\n",
       "      <td>149105.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162683.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>824</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3</td>\n",
       "      <td>27517.15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2746.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>834</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9</td>\n",
       "      <td>130169.27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93112.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>838</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4</td>\n",
       "      <td>103267.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78310.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>841</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9</td>\n",
       "      <td>108131.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60830.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>847</td>\n",
       "      <td>66.0</td>\n",
       "      <td>7</td>\n",
       "      <td>123760.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53157.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>849</td>\n",
       "      <td>69.0</td>\n",
       "      <td>7</td>\n",
       "      <td>71996.09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>139065.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>850</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8</td>\n",
       "      <td>169832.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184107.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>850</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>127120.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118929.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>850</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64350.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>850</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5</td>\n",
       "      <td>169445.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>186335.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>850</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>96947.58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62282.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>850</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>705.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8458</th>\n",
       "      <td>850</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>107236.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9646</th>\n",
       "      <td>850</td>\n",
       "      <td>71.0</td>\n",
       "      <td>10</td>\n",
       "      <td>69608.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97893.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>850</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59568.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7956</th>\n",
       "      <td>850</td>\n",
       "      <td>81.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44827.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore   Age     ...       Geography_Spain  Gender_Male\n",
       "1838          350  39.0     ...                     0            1\n",
       "9624          350  40.0     ...                     0            0\n",
       "8723          350  51.0     ...                     0            1\n",
       "1631          350  54.0     ...                     1            1\n",
       "8762          350  60.0     ...                     0            0\n",
       "2473          351  57.0     ...                     0            0\n",
       "1962          358  52.0     ...                     1            0\n",
       "1405          359  44.0     ...                     0            0\n",
       "1193          363  28.0     ...                     1            0\n",
       "2579          365  30.0     ...                     0            1\n",
       "8154          367  42.0     ...                     1            1\n",
       "9356          373  42.0     ...                     0            1\n",
       "7             376  29.0     ...                     0            0\n",
       "942           376  46.0     ...                     0            0\n",
       "9210          382  36.0     ...                     1            1\n",
       "3531          408  84.0     ...                     0            0\n",
       "7138          430  66.0     ...                     0            0\n",
       "3909          431  63.0     ...                     0            1\n",
       "8156          434  71.0     ...                     0            1\n",
       "5132          439  66.0     ...                     0            0\n",
       "9765          445  64.0     ...                     0            1\n",
       "3497          456  63.0     ...                     0            0\n",
       "9292          461  74.0     ...                     0            0\n",
       "1981          476  69.0     ...                     1            0\n",
       "2615          486  63.0     ...                     0            1\n",
       "5020          491  68.0     ...                     0            0\n",
       "6357          491  68.0     ...                     0            0\n",
       "4849          491  70.0     ...                     0            1\n",
       "7302          491  72.0     ...                     0            0\n",
       "5581          494  67.0     ...                     1            1\n",
       "...           ...   ...     ...                   ...          ...\n",
       "4051          793  63.0     ...                     0            0\n",
       "1901          796  67.0     ...                     1            1\n",
       "5255          799  63.0     ...                     0            0\n",
       "7194          799  70.0     ...                     0            1\n",
       "6515          803  65.0     ...                     0            0\n",
       "5197          804  71.0     ...                     0            0\n",
       "7139          806  67.0     ...                     0            0\n",
       "6715          808  67.0     ...                     1            0\n",
       "3994          809  80.0     ...                     1            1\n",
       "9402          810  69.0     ...                     0            1\n",
       "7523          814  72.0     ...                     1            0\n",
       "736           816  67.0     ...                     1            1\n",
       "7057          818  72.0     ...                     0            0\n",
       "4801          823  71.0     ...                     0            1\n",
       "6721          824  77.0     ...                     0            1\n",
       "5000          834  68.0     ...                     0            0\n",
       "3541          838  67.0     ...                     1            0\n",
       "2012          841  74.0     ...                     0            1\n",
       "6626          847  66.0     ...                     0            1\n",
       "3527          849  69.0     ...                     0            1\n",
       "2053          850  63.0     ...                     0            1\n",
       "6709          850  66.0     ...                     0            0\n",
       "1457          850  66.0     ...                     0            1\n",
       "9688          850  68.0     ...                     0            1\n",
       "4463          850  70.0     ...                     0            0\n",
       "559           850  70.0     ...                     1            0\n",
       "8458          850  71.0     ...                     0            0\n",
       "9646          850  71.0     ...                     1            1\n",
       "7526          850  81.0     ...                     0            0\n",
       "7956          850  81.0     ...                     0            1\n",
       "\n",
       "[374 rows x 12 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the outliers which were removed (In all, 374 eligible outlier rows were removed)\n",
    "outlierDf = pd.concat([data, capDf])\n",
    "outlierDf = outlierDf.reset_index(drop=True)\n",
    "df_gpby = outlierDf.groupby(list(outlierDf.columns))\n",
    "idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]\n",
    "outlierDf.reindex(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target set would be the 'isActive' column since it checks whether bank customer is active, which would be useful for\n",
    "validating the possibility of a bank customer staying or leaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9626 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      "CreditScore          9626 non-null int64\n",
      "Age                  9626 non-null float64\n",
      "Tenure               9626 non-null int64\n",
      "Balance              9626 non-null float64\n",
      "NumOfProducts        9626 non-null int64\n",
      "HasCrCard            9626 non-null int64\n",
      "IsActiveMember       9626 non-null int64\n",
      "EstimatedSalary      9626 non-null float64\n",
      "Exited               9626 non-null int64\n",
      "Geography_Germany    9626 non-null int64\n",
      "Geography_Spain      9626 non-null int64\n",
      "Gender_Male          9626 non-null int64\n",
      "dtypes: float64(3), int64(9)\n",
      "memory usage: 977.6 KB\n"
     ]
    }
   ],
   "source": [
    "capDf.info()\n",
    "X = capDf.loc[:, capDf.columns != 'IsActiveMember']\n",
    "Y = capDf.loc[:, capDf.columns == 'IsActiveMember']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9626 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "CreditScore          9626 non-null int64\n",
      "Age                  9626 non-null float64\n",
      "Tenure               9626 non-null int64\n",
      "Balance              9626 non-null float64\n",
      "NumOfProducts        9626 non-null int64\n",
      "HasCrCard            9626 non-null int64\n",
      "EstimatedSalary      9626 non-null float64\n",
      "Exited               9626 non-null int64\n",
      "Geography_Germany    9626 non-null int64\n",
      "Geography_Spain      9626 non-null int64\n",
      "Gender_Male          9626 non-null int64\n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 902.4 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9626 entries, 0 to 9999\n",
      "Data columns (total 1 columns):\n",
      "IsActiveMember    9626 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 150.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X.info())\n",
    "print(Y.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.949542</td>\n",
       "      <td>-1.446948</td>\n",
       "      <td>-0.355142</td>\n",
       "      <td>0.890415</td>\n",
       "      <td>0.814713</td>\n",
       "      <td>0.646244</td>\n",
       "      <td>0.523978</td>\n",
       "      <td>-0.504032</td>\n",
       "      <td>-0.583863</td>\n",
       "      <td>-0.573352</td>\n",
       "      <td>-1.091757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age     ...       Geography_Spain  Gender_Male\n",
       "0     0.949542 -1.446948     ...             -0.573352    -1.091757\n",
       "\n",
       "[1 rows x 11 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.158655</td>\n",
       "      <td>-0.084361</td>\n",
       "      <td>-1.046646</td>\n",
       "      <td>1.31239</td>\n",
       "      <td>-0.923582</td>\n",
       "      <td>-1.547404</td>\n",
       "      <td>-0.109943</td>\n",
       "      <td>-0.504032</td>\n",
       "      <td>1.712732</td>\n",
       "      <td>-0.573352</td>\n",
       "      <td>-1.091757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age     ...       Geography_Spain  Gender_Male\n",
       "0     0.158655 -0.084361     ...             -0.573352    -1.091757\n",
       "\n",
       "[1 rows x 11 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(30, input_dim = 11, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 53.58% (1.14%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Training Dataset\n",
    "estimator = keras.wrappers.scikit_learn.KerasClassifier(build_fn = create_baseline, epochs = 50, batch_size = 5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "results = cross_val_score(estimator, np.array(X_train_scaled), np.array(y_train), cv = kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model_new = tf.keras.models.Sequential()\n",
    "\n",
    "#Normalize the data\n",
    "model_new.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model_new.add(keras.layers.Dense(30, input_dim = 11, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model_new.add(keras.layers.Dense(1, input_dim = 11, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "#Add Dense Layer which provides 2 Outputs after applying sigmoid\n",
    "model_new.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Comile the model\n",
    "model_new.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6738 samples, validate on 2888 samples\n",
      "Epoch 1/50\n",
      "6738/6738 [==============================] - 1s 79us/sample - loss: 0.6930 - acc: 0.5190 - val_loss: 0.6928 - val_acc: 0.5062\n",
      "Epoch 2/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6929 - acc: 0.5024 - val_loss: 0.6928 - val_acc: 0.5062\n",
      "Epoch 3/50\n",
      "6738/6738 [==============================] - 0s 2us/sample - loss: 0.6928 - acc: 0.5024 - val_loss: 0.6927 - val_acc: 0.5062\n",
      "Epoch 4/50\n",
      "6738/6738 [==============================] - 0s 2us/sample - loss: 0.6927 - acc: 0.5024 - val_loss: 0.6926 - val_acc: 0.5062\n",
      "Epoch 5/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6926 - acc: 0.5024 - val_loss: 0.6925 - val_acc: 0.5062\n",
      "Epoch 6/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6925 - acc: 0.5024 - val_loss: 0.6924 - val_acc: 0.5062\n",
      "Epoch 7/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6924 - acc: 0.5024 - val_loss: 0.6923 - val_acc: 0.5329\n",
      "Epoch 8/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6922 - acc: 0.5353 - val_loss: 0.6922 - val_acc: 0.5360\n",
      "Epoch 9/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6921 - acc: 0.5367 - val_loss: 0.6920 - val_acc: 0.5405\n",
      "Epoch 10/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6919 - acc: 0.5365 - val_loss: 0.6919 - val_acc: 0.5433\n",
      "Epoch 11/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6917 - acc: 0.5381 - val_loss: 0.6917 - val_acc: 0.5474\n",
      "Epoch 12/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6916 - acc: 0.5362 - val_loss: 0.6916 - val_acc: 0.5492\n",
      "Epoch 13/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6914 - acc: 0.5404 - val_loss: 0.6914 - val_acc: 0.5502\n",
      "Epoch 14/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6912 - acc: 0.5401 - val_loss: 0.6913 - val_acc: 0.5506\n",
      "Epoch 15/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6910 - acc: 0.5404 - val_loss: 0.6911 - val_acc: 0.5506\n",
      "Epoch 16/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6909 - acc: 0.5392 - val_loss: 0.6910 - val_acc: 0.5499\n",
      "Epoch 17/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6907 - acc: 0.5398 - val_loss: 0.6908 - val_acc: 0.5481\n",
      "Epoch 18/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6905 - acc: 0.5407 - val_loss: 0.6907 - val_acc: 0.5474\n",
      "Epoch 19/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6903 - acc: 0.5399 - val_loss: 0.6906 - val_acc: 0.5474\n",
      "Epoch 20/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6902 - acc: 0.5399 - val_loss: 0.6904 - val_acc: 0.5461\n",
      "Epoch 21/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6900 - acc: 0.5439 - val_loss: 0.6903 - val_acc: 0.5467\n",
      "Epoch 22/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6898 - acc: 0.5450 - val_loss: 0.6902 - val_acc: 0.5467\n",
      "Epoch 23/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6896 - acc: 0.5457 - val_loss: 0.6900 - val_acc: 0.5474\n",
      "Epoch 24/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6894 - acc: 0.5472 - val_loss: 0.6899 - val_acc: 0.5478\n",
      "Epoch 25/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6892 - acc: 0.5485 - val_loss: 0.6898 - val_acc: 0.5495\n",
      "Epoch 26/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6891 - acc: 0.5488 - val_loss: 0.6896 - val_acc: 0.5499\n",
      "Epoch 27/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6889 - acc: 0.5490 - val_loss: 0.6895 - val_acc: 0.5530\n",
      "Epoch 28/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6887 - acc: 0.5493 - val_loss: 0.6894 - val_acc: 0.5526\n",
      "Epoch 29/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6885 - acc: 0.5512 - val_loss: 0.6892 - val_acc: 0.5519\n",
      "Epoch 30/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6883 - acc: 0.5515 - val_loss: 0.6891 - val_acc: 0.5519\n",
      "Epoch 31/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6881 - acc: 0.5518 - val_loss: 0.6889 - val_acc: 0.5530\n",
      "Epoch 32/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6879 - acc: 0.5516 - val_loss: 0.6888 - val_acc: 0.5547\n",
      "Epoch 33/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6877 - acc: 0.5522 - val_loss: 0.6886 - val_acc: 0.5564\n",
      "Epoch 34/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6875 - acc: 0.5527 - val_loss: 0.6884 - val_acc: 0.5564\n",
      "Epoch 35/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6873 - acc: 0.5524 - val_loss: 0.6883 - val_acc: 0.5571\n",
      "Epoch 36/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6871 - acc: 0.5525 - val_loss: 0.6881 - val_acc: 0.5564\n",
      "Epoch 37/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6869 - acc: 0.5525 - val_loss: 0.6880 - val_acc: 0.5557\n",
      "Epoch 38/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6867 - acc: 0.5525 - val_loss: 0.6878 - val_acc: 0.5561\n",
      "Epoch 39/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6865 - acc: 0.5524 - val_loss: 0.6877 - val_acc: 0.5571\n",
      "Epoch 40/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6863 - acc: 0.5534 - val_loss: 0.6875 - val_acc: 0.5571\n",
      "Epoch 41/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6861 - acc: 0.5543 - val_loss: 0.6874 - val_acc: 0.5568\n",
      "Epoch 42/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6859 - acc: 0.5549 - val_loss: 0.6872 - val_acc: 0.5564\n",
      "Epoch 43/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6857 - acc: 0.5557 - val_loss: 0.6871 - val_acc: 0.5568\n",
      "Epoch 44/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6855 - acc: 0.5560 - val_loss: 0.6870 - val_acc: 0.5561\n",
      "Epoch 45/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6853 - acc: 0.5551 - val_loss: 0.6868 - val_acc: 0.5557\n",
      "Epoch 46/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6851 - acc: 0.5539 - val_loss: 0.6867 - val_acc: 0.5533\n",
      "Epoch 47/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6848 - acc: 0.5539 - val_loss: 0.6866 - val_acc: 0.5523\n",
      "Epoch 48/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6846 - acc: 0.5548 - val_loss: 0.6864 - val_acc: 0.5526\n",
      "Epoch 49/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6844 - acc: 0.5554 - val_loss: 0.6863 - val_acc: 0.5547\n",
      "Epoch 50/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6842 - acc: 0.5564 - val_loss: 0.6862 - val_acc: 0.5554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3e56fc88>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.fit(np.array(X_train_scaled), np.array(y_train), \n",
    "          validation_data=(np.array(X_test_scaled), np.array(y_test)), \n",
    "          epochs = 50,\n",
    "          batch_size=X_train_scaled.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, Old and New Models provide similar accuracy with the highest being 53.6% using crossvalidation on the Keras Scikit Learn Classification Wrapper and 55.6% manually using the adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Let us try with Grid Search, with different learning rates on SGD\n",
    "#Initialize Sequential model\n",
    "model_new_addtl = tf.keras.models.Sequential()\n",
    "\n",
    "#Normalize the data\n",
    "model_new_addtl.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model_new_addtl.add(keras.layers.Dense(30, input_dim = 11, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model_new_addtl.add(keras.layers.Dense(1, input_dim = 11, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "#Add Dense Layer which provides 2 Outputs after applying sigmoid\n",
    "model_new_addtl.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr = 0.01)\n",
    "\n",
    "#Comile the model\n",
    "model_new_addtl.compile(optimizer = sgd, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6738 samples, validate on 2888 samples\n",
      "Epoch 1/50\n",
      "6738/6738 [==============================] - 0s 71us/sample - loss: 0.6931 - acc: 0.4981 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 2/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 3/50\n",
      "6738/6738 [==============================] - 0s 2us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 4/50\n",
      "6738/6738 [==============================] - 0s 2us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 5/50\n",
      "6738/6738 [==============================] - 0s 2us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 6/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 7/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 8/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 9/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 10/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6932 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 11/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 12/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 13/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 14/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 15/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 16/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 17/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 18/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6932 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 19/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 20/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 21/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 22/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 23/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 24/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 25/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 26/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 27/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 28/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 29/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6932 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 30/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 31/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 32/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 33/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 34/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 35/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 36/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 37/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 38/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 39/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 40/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 41/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 42/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 43/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 44/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 45/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 46/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 47/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 48/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 49/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 50/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3de93e80>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new_addtl.fit(np.array(X_train_scaled), np.array(y_train), \n",
    "          validation_data=(np.array(X_test_scaled), np.array(y_test)), \n",
    "          epochs = 50,\n",
    "          batch_size=X_train_scaled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fall in accuracy using sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increasing the Learning Rate\n",
    "sgd = keras.optimizers.SGD(lr = 0.1)\n",
    "\n",
    "#Comile the model\n",
    "model_new_addtl.compile(optimizer = sgd, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6738 samples, validate on 2888 samples\n",
      "Epoch 1/50\n",
      "6738/6738 [==============================] - 0s 73us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 2/50\n",
      "6738/6738 [==============================] - 0s 2us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 3/50\n",
      "6738/6738 [==============================] - 0s 2us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 4/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 5/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 6/50\n",
      "6738/6738 [==============================] - 0s 2us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 7/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 8/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 9/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 10/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 11/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 12/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 13/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 14/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 15/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 16/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 17/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 18/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 19/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 20/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 21/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 22/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 23/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 24/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 25/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 26/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 27/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 28/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 29/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 30/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 31/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 32/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 33/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 34/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 35/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 36/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 37/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 38/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 39/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 40/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 41/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 42/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 43/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 44/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 45/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 46/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 47/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 48/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 49/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 50/50\n",
      "6738/6738 [==============================] - 0s 1us/sample - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6931 - val_acc: 0.5062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3f3b8208>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new_addtl.fit(np.array(X_train_scaled), np.array(y_train), \n",
    "          validation_data=(np.array(X_test_scaled), np.array(y_test)), \n",
    "          epochs = 50,\n",
    "          batch_size=X_train_scaled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Model Fitting with Adam Optimizer and Batch Normalization provided the best results with a highest accuracy on test set of 55.6% while using Stratified K Fold Cross Validation proved computationally expensive at the same time compromising on the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
